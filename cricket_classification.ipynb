{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cricket Image Classification: Feature Extraction & Model Training\n",
                "\n",
                "This notebook demonstrates the complete pipeline for classifying cricket image cells (Ball, Bat, Stump, Background).\n",
                "\n",
                "## Steps:\n",
                "1.  **Setup**: Install dependencies.\n",
                "2.  **Data Loading**: Load images and labels.\n",
                "3.  **Feature Visualization**: Inspect HOG, Color, and Shape features.\n",
                "4.  **Feature Extraction**: Build the feature matrix.\n",
                "5.  **Model Training**: Train SVM, Random Forest, and MLP classifiers.\n",
                "6.  **Evaluation**: Analyze performance metrics."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install scikit-image opencv-python pandas matplotlib scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import cv2\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from skimage.feature import hog\n",
                "from skimage import exposure\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import seaborn as sns\n",
                "\n",
                "# Configuration\n",
                "IMG_WIDTH = 800\n",
                "IMG_HEIGHT = 600\n",
                "GRID_ROWS = 8\n",
                "GRID_COLS = 8\n",
                "CELL_W = IMG_WIDTH // GRID_COLS\n",
                "CELL_H = IMG_HEIGHT // GRID_ROWS\n",
                "\n",
                "# Paths (Adjust if using Google Drive)\n",
                "PROCESSED_DIR = \"processed_images\"\n",
                "LABELS_FILE = \"labels.csv\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading\n",
                "Ensure `processed_images` folder and `labels.csv` are uploaded to the Colab environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(labels_file, image_dir):\n",
                "    if not os.path.exists(labels_file):\n",
                "        print(f\"Error: {labels_file} not found.\")\n",
                "        return None\n",
                "    \n",
                "    df = pd.read_csv(labels_file)\n",
                "    print(f\"Loaded labels for {len(df)} images.\")\n",
                "    return df\n",
                "\n",
                "df = load_data(LABELS_FILE, PROCESSED_DIR)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Visualization\n",
                "Let's inspect the features for a single cell to understand what the model sees."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_features(image_name, row_idx, col_idx):\n",
                "    img_path = os.path.join(PROCESSED_DIR, image_name)\n",
                "    if not os.path.exists(img_path):\n",
                "        print(f\"Image {image_name} not found.\")\n",
                "        return\n",
                "        \n",
                "    img = cv2.imread(img_path)\n",
                "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Extract Cell\n",
                "    x1 = col_idx * CELL_W\n",
                "    y1 = row_idx * CELL_H\n",
                "    x2 = x1 + CELL_W\n",
                "    y2 = y1 + CELL_H\n",
                "    cell = img[y1:y2, x1:x2]\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "    \n",
                "    # 1. Original\n",
                "    axes[0, 0].imshow(cell)\n",
                "    axes[0, 0].set_title(\"Original Cell\")\n",
                "    axes[0, 0].axis('off')\n",
                "    \n",
                "    # 2. HOG\n",
                "    fd, hog_image = hog(cell, orientations=9, pixels_per_cell=(8, 8),\n",
                "                        cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
                "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
                "    axes[0, 1].imshow(hog_image_rescaled, cmap='gray')\n",
                "    axes[0, 1].set_title(\"HOG Features\")\n",
                "    axes[0, 1].axis('off')\n",
                "    \n",
                "    # 3. Color Histogram\n",
                "    axes[0, 2].set_title(\"Color Histogram\")\n",
                "    colors = ('r', 'g', 'b')\n",
                "    for i, color in enumerate(colors):\n",
                "        hist = cv2.calcHist([cell], [i], None, [32], [0, 256])\n",
                "        axes[0, 2].plot(hist, color=color)\n",
                "        \n",
                "    # 4. Edge Detection\n",
                "    gray = cv2.cvtColor(cell, cv2.COLOR_RGB2GRAY)\n",
                "    edges = cv2.Canny(gray, 50, 150)\n",
                "    axes[1, 0].imshow(edges, cmap='gray')\n",
                "    axes[1, 0].set_title(\"Canny Edges\")\n",
                "    axes[1, 0].axis('off')\n",
                "    \n",
                "    # 5. Hough Lines\n",
                "    lines_img = cell.copy()\n",
                "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=30, minLineLength=20, maxLineGap=10)\n",
                "    if lines is not None:\n",
                "        for line in lines:\n",
                "            x1_l, y1_l, x2_l, y2_l = line[0]\n",
                "            cv2.line(lines_img, (x1_l, y1_l), (x2_l, y2_l), (0, 255, 0), 2)\n",
                "    axes[1, 1].imshow(lines_img)\n",
                "    axes[1, 1].set_title(\"Hough Lines\")\n",
                "    axes[1, 1].axis('off')\n",
                "    \n",
                "    # 6. Hough Circles\n",
                "    circles_img = cell.copy()\n",
                "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
                "                               param1=50, param2=30, minRadius=5, maxRadius=50)\n",
                "    if circles is not None:\n",
                "        circles = np.uint16(np.around(circles))\n",
                "        for i in circles[0, :]:\n",
                "            cv2.circle(circles_img, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
                "            cv2.circle(circles_img, (i[0], i[1]), 2, (255, 0, 0), 3)\n",
                "    axes[1, 2].imshow(circles_img)\n",
                "    axes[1, 2].set_title(\"Hough Circles\")\n",
                "    axes[1, 2].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Visualize a sample cell (Row 4, Col 4 of first image)\n",
                "if df is not None and not df.empty:\n",
                "    visualize_features(df.iloc[0]['ImageFileName'], 3, 3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Extraction\n",
                "We will now iterate through all images and extract features for every labeled cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_features(df):\n",
                "    features_list = []\n",
                "    labels_list = []\n",
                "    \n",
                "    print(\"Starting feature extraction...\")\n",
                "    \n",
                "    for idx, row in df.iterrows():\n",
                "        img_name = row['ImageFileName']\n",
                "        img_path = os.path.join(PROCESSED_DIR, img_name)\n",
                "        \n",
                "        if not os.path.exists(img_path):\n",
                "            continue\n",
                "            \n",
                "        img = cv2.imread(img_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        for i in range(64):\n",
                "            label = row[f\"c{i+1:02d}\"]\n",
                "            if label == 0: # Skip background/unlabeled if desired, or keep as class 0\n",
                "                # For this task, let's keep 0 as 'Background' class\n",
                "                pass\n",
                "                \n",
                "            r = i // GRID_COLS\n",
                "            c = i % GRID_COLS\n",
                "            \n",
                "            x1 = c * CELL_W\n",
                "            y1 = r * CELL_H\n",
                "            x2 = x1 + CELL_W\n",
                "            y2 = y1 + CELL_H\n",
                "            \n",
                "            cell = img[y1:y2, x1:x2]\n",
                "            \n",
                "            # --- Feature 1: HOG ---\n",
                "            fd = hog(cell, orientations=9, pixels_per_cell=(8, 8),\n",
                "                     cells_per_block=(2, 2), visualize=False, channel_axis=-1)\n",
                "            \n",
                "            # --- Feature 2: Color Histogram ---\n",
                "            hist_features = []\n",
                "            for ch in range(3):\n",
                "                hist = cv2.calcHist([cell], [ch], None, [32], [0, 256])\n",
                "                hist = cv2.normalize(hist, hist).flatten()\n",
                "                hist_features.extend(hist)\n",
                "                \n",
                "            # --- Feature 3: Shape Counts ---\n",
                "            gray = cv2.cvtColor(cell, cv2.COLOR_RGB2GRAY)\n",
                "            edges = cv2.Canny(gray, 50, 150)\n",
                "            \n",
                "            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=30, minLineLength=20, maxLineGap=10)\n",
                "            num_lines = len(lines) if lines is not None else 0\n",
                "            \n",
                "            circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20,\n",
                "                                       param1=50, param2=30, minRadius=5, maxRadius=50)\n",
                "            num_circles = len(circles[0, :]) if circles is not None else 0\n",
                "            \n",
                "            # Combine\n",
                "            combined = np.concatenate([fd, hist_features, [num_lines, num_circles]])\n",
                "            \n",
                "            features_list.append(combined)\n",
                "            labels_list.append(label)\n",
                "            \n",
                "        if (idx + 1) % 5 == 0:\n",
                "            print(f\"Processed {idx + 1} images...\")\n",
                "            \n",
                "    return np.array(features_list), np.array(labels_list)\n",
                "\n",
                "X, y = extract_features(df)\n",
                "print(f\"Feature Matrix Shape: {X.shape}\")\n",
                "print(f\"Labels Shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training\n",
                "We will split the data and train multiple classifiers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Scale Features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"Train set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Support Vector Machine\n",
                "print(\"Training SVM...\")\n",
                "svm_model = SVC(kernel='rbf', C=10, gamma='scale')\n",
                "svm_model.fit(X_train_scaled, y_train)\n",
                "svm_pred = svm_model.predict(X_test_scaled)\n",
                "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Random Forest\n",
                "print(\"Training Random Forest...\")\n",
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_model.fit(X_train_scaled, y_train)\n",
                "rf_pred = rf_model.predict(X_test_scaled)\n",
                "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. MLP (Neural Network)\n",
                "print(\"Training MLP...\")\n",
                "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
                "mlp_model.fit(X_train_scaled, y_train)\n",
                "mlp_pred = mlp_model.predict(X_test_scaled)\n",
                "print(\"MLP Accuracy:\", accuracy_score(y_test, mlp_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation\n",
                "Visualizing the performance of the best model (likely Random Forest or SVM)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(y_true, y_pred, title):\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "                xticklabels=['None', 'Ball', 'Bat', 'Stump'], \n",
                "                yticklabels=['None', 'Ball', 'Bat', 'Stump'])\n",
                "    plt.title(title)\n",
                "    plt.ylabel('True Label')\n",
                "    plt.xlabel('Predicted Label')\n",
                "    plt.show()\n",
                "\n",
                "print(\"SVM Classification Report:\")\n",
                "print(classification_report(y_test, svm_pred, target_names=['None', 'Ball', 'Bat', 'Stump']))\n",
                "plot_confusion_matrix(y_test, svm_pred, \"SVM Confusion Matrix\")\n",
                "\n",
                "print(\"Random Forest Classification Report:\")\n",
                "print(classification_report(y_test, rf_pred, target_names=['None', 'Ball', 'Bat', 'Stump']))\n",
                "plot_confusion_matrix(y_test, rf_pred, \"Random Forest Confusion Matrix\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}